{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IS53051A Machine Learning Assignment\n",
    "### Jake Tyler [student number] & Sonny Holland [student number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up our notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1806,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1807,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('datcw_na.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data inspection and Visualisations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data inspection\n",
    "\n",
    "First we take a brief look at our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1808,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X0    X1      X2      X3      X4    X5    X6   X7   X8      Y\n",
      "0  C3  1.19  622.55     NaN   89.31  7.00  1.98  0.0  0.0  15.55\n",
      "1  C1  1.19  622.55  323.40  109.15  7.70  3.00  0.0  0.0  15.55\n",
      "2  C1  0.88  463.05  291.06   99.23  5.67  4.40  0.0  0.0  15.55\n",
      "3  C2  0.79  509.36  291.06  121.28  6.30  4.05  0.0  0.0  15.55\n",
      "4  C1  0.89  507.15  385.39  121.28  7.70  2.00  0.0  0.0  20.84 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   X0      768 non-null    object \n",
      " 1   X1      768 non-null    float64\n",
      " 2   X2      768 non-null    float64\n",
      " 3   X3      728 non-null    float64\n",
      " 4   X4      768 non-null    float64\n",
      " 5   X5      768 non-null    float64\n",
      " 6   X6      768 non-null    float64\n",
      " 7   X7      768 non-null    float64\n",
      " 8   X8      768 non-null    float64\n",
      " 9   Y       768 non-null    float64\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 60.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head(), \"\\n\")\n",
    "print(dataset.info())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### column 'X3' has missing values and column 'X0' is non-numerical,\n",
    "\n",
    "We can determine that column 'X3' has 768 entries. Additionally, using the .isna().sum() method we can identify that 40 values are missing from these entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1809,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X3 number of entries: 768\n",
      "X3 missing values: 40\n"
     ]
    }
   ],
   "source": [
    "print(\"X3 number of entries:\", dataset[\"X3\"].size)\n",
    "print(\"X3 missing values:\", dataset['X3'].isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can determine that 'X0' is a nominal/categorical variable. The value_counts() method also provides the elements in descending order, starting with the most frequently occurring one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0 value counts:\n",
      "C2    265\n",
      "C3    260\n",
      "C1    243\n",
      "Name: X0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"X0 value counts:\")\n",
    "print(dataset[\"X0\"].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assessing options for handling missing values in our dataset before pre-processing,\n",
    "\n",
    "If the amount of missing data is small and randomly distributed, it may be appropriate to replace missing values with the mean of the non-missing values. This can preserve the overall distribution of the data and prevent the loss of valuable information. \n",
    "\n",
    "If the missing data is large or non-random, it may be better to drop the missing values altogether. This can help prevent the introduction of bias into the analysis and reduce the risk of making incorrect predictions. However, dropping missing values can also result in a loss of information and reduce the sample size, potentially reducing the accuracy of the model.\n",
    "\n",
    "Here, we can perform some basic forms of analysis to investigate whether the missing data is small and randomly distributed:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### percentage of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1811,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of missing values:\n",
      "X0    0.000000\n",
      "X1    0.000000\n",
      "X2    0.000000\n",
      "X3    0.052083\n",
      "X4    0.000000\n",
      "X5    0.000000\n",
      "X6    0.000000\n",
      "X7    0.000000\n",
      "X8    0.000000\n",
      "Y     0.000000\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"percentage of missing values:\")\n",
    "print(dataset.isna().sum() / dataset.shape[0], \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the percentage of missing values is less than 5% for all columns, it seems reasonable to assume that the missing values are small. While the 'X3' column has the highest percentage of missing values and exceeds the 5% threshold, the difference is small enough to still consider it small. However, it's important to note that the missing data may still have an impact on the analysis, and a decision has not been made on how to handle it.\n",
    "\n",
    "To determine if the missing data should be kept or not, we will need to examine its correlations with the target variable.\n",
    "\n",
    "Additionally, we may need to perform a sensitivity analysis to assess if the results are affected by the missing data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distribution of data\n",
    "\n",
    "To understand the distribution of the non-missing values, we can use a histogram to gain some visual insights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1812,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dataset['X3'], bins=20)\n",
    "plt.xlabel('X3 values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate a example datasets for visual comparison,\n",
    "\n",
    "we can examine whether the above histogram is random or non-random with a comparison against some example histograms below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random dataset example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1813,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.random.randn(100)\n",
    "plt.hist(data, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non-random dataset example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1814,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.random.normal(0, 1, 100) ** 3\n",
    "plt.hist(data, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from the above examples we can determine that the missing values in column X3 are small and randomly distributed, we can consider imputing the missing values with a reasonable method, such as mean imputation or interpolation, to fill in the gaps in the data.\n",
    "\n",
    "Before deciding on an imputation method, it would be a good idea to analyze the relationship between X3 and the target variable to see if the missing values have a significant impact on the results. You can use correlation analysis or other statistical methods to determine the impact of missing values.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assessing options for handling categorical data in our dataset before pre-processing,\n",
    "\n",
    "There are several techniques to handle categorical data, including:\n",
    "\n",
    "* Label encoding: In this technique, each category is assigned a unique numerical value. For example, if we have a categorical feature \"color\" with values \"red\", \"green\", and \"blue\", we can assign them numerical values 1, 2, and 3, respectively. Label encoding is simple to implement but can be problematic if the numerical values imply an ordering or magnitude that does not exist in the categorical feature.\n",
    "\n",
    "* One-hot encoding: In this technique, a new binary column is created for each category in the categorical feature. Each row in the dataset is assigned a 1 in the corresponding category column and 0 in all other category columns. For example, if we have a categorical feature \"color\" with values \"red\", \"green\", and \"blue\", we can create three new columns \"color_red\", \"color_green\", and \"color_blue\" and assign binary values based on the presence or absence of each category in each row.\n",
    "\n",
    "* Binary encoding: This technique is similar to one-hot encoding, but it reduces the number of columns required to represent categorical data. In binary encoding, the categories are first encoded as integers and then converted to binary code. For example, if we have a categorical feature \"color\" with values \"red\", \"green\", and \"blue\", we can first assign them numerical values 1, 2, and 3, respectively, and then convert them to binary code 001, 010, and 100, respectively.\n",
    "\n",
    "* Count encoding: In this technique, each category is replaced with the count of the number of times it appears in the dataset. This technique can be useful if the frequency of occurrence of each category is important for the analysis.\n",
    "\n",
    "* Target encoding: In this technique, each category is replaced with the mean of the target variable for that category. This technique can be useful for classification problems where the target variable is a categorical variable.\n",
    "\n",
    "Overall, the appropriate technique to use for handling categorical data depends on the specifics of your problem, the number of categories, and the type of machine learning algorithm being used. It is important to experiment with different techniques and evaluate their performance on the problem at hand.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now that you know which columns have missing values, you can choose how to handle them.\n",
    " Some common techniques for handling missing values include:\n",
    " Dropping rows or columns with missing values\n",
    " Filling missing values with a fixed value (e.g., 0, mean, median)\n",
    " Using an imputation method to predict missing values based on other variables in the dataset\n",
    " The choice of technique will depend on the specific requirements of your machine learning problem\n",
    " and the characteristics of your dataset.\n",
    " Some common techniques for handling missing values include:\n",
    " - Dropping rows or columns with missing values\n",
    " - Filling missing values with a fixed value (e.g., 0, mean, median)\n",
    " - Using an imputation method to predict missing values based on other variables in the dataset\n",
    " here are some questions that can help you choose an appropriate technique for handling missing values:\n",
    " - How many missing values do you have in each column? If a column has a large percentage of missing values,\n",
    " it might be better to drop that column altogether, rather than trying to fill in the missing values.\n",
    " - What is the nature of the missing values in your dataset? Are they missing at random (MAR),\n",
    " missing completely at random (MCAR), or missing not at random (MNAR)? This can help you decide which \n",
    " imputation method to use.\n",
    " - Are there any correlations between the missing values and other variables in the dataset? If so,\n",
    " you might be able to use these correlations to impute the missing values.\n",
    " - What type of data is in the column with missing values? If it's categorical data,\n",
    " you might use a mode imputation technique, where you fill in missing values with the most common\n",
    " value in the column. If it's continuous data, you might use mean, median or other statistical\n",
    " imputation techniques.\n",
    " - What is the impact of removing or imputing missing values on your machine learning model?\n",
    " Depending on your dataset and your model, removing or imputing missing values might improve or\n",
    " degrade the performance of your model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " WE CAN CHECK THE CORRELATIONS BETWEEN THE MISSING VALUES AND OTHER VARIABLES IN THE DATASET\n",
    " USING THE CORRELATION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1815,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yl/xlfszlh139sb6qg5_gn41sdc0000gn/T/ipykernel_24231/3756635859.py:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  corr_matrix = dataset.corr()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Y     1.000000\n",
       "X5    0.815769\n",
       "X1    0.454177\n",
       "X3    0.312449\n",
       "X7    0.255901\n",
       "X8    0.087106\n",
       "X6    0.001340\n",
       "X2   -0.481192\n",
       "X4   -0.771040\n",
       "Name: Y, dtype: float64"
      ]
     },
     "execution_count": 1815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a correlation matrix\n",
    "corr_matrix = dataset.corr()\n",
    "corr_matrix[\"Y\"].sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the information provided, it seems reasonable to replace the missing values in column\n",
    "X3 with the mean value, as the percentage of missing values is relatively low (5.2%).\n",
    "Additionally, X3 appears to have a moderate positive correlation with the target variable Y\n",
    "(correlation coefficient of 0.31), indicating that it may be a useful feature in predicting Y\n",
    "However, before deciding to replace missing values with the mean, it's important to consider the\n",
    "nature of the data and the potential impact of imputing missing values on the analysis results.\n",
    "For instance, if X3 has a significant number of extreme values or outliers, then the mean may\n",
    "not be a representative measure of central tendency, and imputing missing values with the mean\n",
    "could distort the distribution of the data\n",
    "Therefore, it's important to carefully evaluate the data and consider other imputation methods,\n",
    "such as using a regression model to predict missing values based on the values of other variables,\n",
    "if appropriate\n",
    "However, it's important to note that the impact of the missing values on the analysis results\n",
    "should be carefully evaluated. If the missing values are not missing at random, and there is\n",
    "a systematic difference between the missing and non-missing values, then replacing the missing\n",
    "values with the mean may introduce bias into the analysis results\n",
    "Therefore, it's important to consider other imputati# on methods and conduct sensitivity analyses\n",
    "to evaluate the impact of missing values on the analysis results.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sensitivty analysis...?????\n",
    "No, this code is not a sensitivity analysis. It is comparing the correlations\n",
    "between X3 and Y with mean imputation and random drop with mean imputation.\n",
    "A sensitivity analysis involves systematically varying the values of one or more\n",
    "input variables and observing the effect on the output variable(s) to determine\n",
    "the sensitivity of the model to changes in those input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1816,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between X3 and Y with mean imputation: 0.305\n",
      "Correlation between X3 and Y with random drop and mean imputation: 0.293\n",
      "Correlation between X3 and Y with median imputation: 0.306\n",
      "Correlation between X3 and Y with random drop and median imputation: 0.288\n"
     ]
    }
   ],
   "source": [
    "# instantiate multiple copies of the dataset to trial different means of imputation\n",
    "dataset_for_mean = dataset.copy()\n",
    "dataset_for_median = dataset.copy()\n",
    "dataset_for_random_drop_mean = dataset.copy()\n",
    "\n",
    "# Calculate the percentage of missing values in X3\n",
    "missing_X3 = dataset_for_random_drop_mean['X3'].isna().mean()\n",
    "\n",
    "# Replace missing values in column X3 with the mean value, and the other copy with the median value\n",
    "median_X3 = dataset_for_median['X3'].median()\n",
    "mean_X3 = dataset_for_mean['X3'].mean()\n",
    "dataset_for_mean['X3'].fillna(mean_X3, inplace=True)\n",
    "dataset_for_median['X3'].fillna(median_X3, inplace=True)\n",
    "\n",
    "# Calculate the correlation between X3 and Y for the mean imputed dataset\n",
    "correlation_with_mean = dataset_for_mean[['X3', 'Y']].corr().loc['X3', 'Y']\n",
    "\n",
    "# Calculate the correlation between X3 and Y for the median imputed dataset\n",
    "correlation_with_median = dataset_for_median[['X3', 'Y']].corr().loc['X3', 'Y']\n",
    "\n",
    "# Create a copy of the dataset with randomly dropped values in X3\n",
    "dataset_for_random_drop_mean['X3'] = dataset_for_random_drop_mean['X3'].apply(lambda x: np.nan if np.random.rand() < missing_X3 else x)\n",
    "\n",
    "# Replace missing values in the random_drop dataset with the mean value\n",
    "dataset_for_random_drop_mean['X3'].fillna(mean_X3, inplace=True)\n",
    "\n",
    "# Replace missing values in the random_drop dataset with the median value\n",
    "dataset_for_random_drop_mean['X3'].fillna(median_X3, inplace=True)\n",
    "\n",
    "# Calculate the correlation between X3 and Y in the random_drop dataset\n",
    "correlation_with_random_drop = dataset_for_random_drop_mean[['X3', 'Y']].corr().loc['X3', 'Y']\n",
    "\n",
    "# Create a copy of the dataset with randomly dropped values in X3 and median imputation\n",
    "dataset_for_random_drop_median = dataset.copy()\n",
    "dataset_for_random_drop_median['X3'] = dataset_for_random_drop_median['X3'].apply(lambda x: np.nan if np.random.rand() < missing_X3 else x)\n",
    "dataset_for_random_drop_median['X3'].fillna(median_X3, inplace=True)\n",
    "\n",
    "# Calculate the correlation between X3 and Y in the random_drop and median imputed dataset\n",
    "correlation_with_random_drop_median = dataset_for_random_drop_median[['X3', 'Y']].corr().loc['X3', 'Y']\n",
    "\n",
    "# Print the correlation results\n",
    "print(f\"Correlation between X3 and Y with mean imputation: {correlation_with_mean:.3f}\")\n",
    "print(f\"Correlation between X3 and Y with random drop and mean imputation: {correlation_with_random_drop:.3f}\")\n",
    "print(f\"Correlation between X3 and Y with median imputation: {correlation_with_median:.3f}\")\n",
    "print(f\"Correlation between X3 and Y with random drop and median imputation: {correlation_with_random_drop_median:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SONNYS BIT: the preceeding code suggests that our choice of imputation has very little affect on the ecology of the dataset, one would expect the use of dropping random values would have a greater impact on the correlation between X3 and Y albeit a negative one, given the ham-fisted nature of this method. For the sake of this exercise we will proceed with the median imputation method. But in other cases it may be worth exploring other means of imputation, such as regression imputation or multiple imputation, to see if they produce more robust results. Alternatively, you may want to consider using analysis methods that are more tolerant to missing data, such as bootstrapping or Bayesian analysis.\n",
    "\n",
    "\n",
    "The correlation between X3 and Y with mean imputation is 0.305 and the correlation between X3 and Y with \n",
    "random drop and mean imputation is 0.286\n",
    "This suggests that imputing missing values in X3 with the mean value has a small positive impact on \n",
    "the correlation between X3 and Y, indicating that there is a weak positive linear relationship between \n",
    "the two variables. However, the difference between the two correlation values is relatively small,\n",
    "suggesting that the choice of imputation method may not have a significant impact on the analysis\n",
    "Based on these results, you can conclude that the two imputation methods produce similar results,\n",
    "but there may be some variability due to missing data. You may then want to explore other\n",
    "imputation methods, such as regression imputation or multiple imputation, to see if they\n",
    "produce more robust results. Alternatively, you may want to consider using analysis methods \n",
    "that are more tolerant to missing data, such as bootstrapping or Bayesian analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing and data splitting in 70% training data, and 30% test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we compute a correlation matrix, this informs our data stratification as we want to make decisions upon the features that correlate best to our target variable. Also down the line, we will perform feature selection, based on the correlation matrix; we will be dropping columns with a low correlation to our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1817,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yl/xlfszlh139sb6qg5_gn41sdc0000gn/T/ipykernel_24231/609732122.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  corr_matrix = dataset.corr()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Y     1.000000\n",
       "X5    0.815769\n",
       "X1    0.454177\n",
       "X3    0.312449\n",
       "X7    0.255901\n",
       "X8    0.087106\n",
       "X6    0.001340\n",
       "X2   -0.481192\n",
       "X4   -0.771040\n",
       "Name: Y, dtype: float64"
      ]
     },
     "execution_count": 1817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = dataset.corr()\n",
    "corr_matrix[\"Y\"].sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test sets, for model training and evaluation, respectively"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may seem counterintuitive to split the data into train and test sets before performing any data preprocessing, however we do this to ensure our `y` variable is shuffled in accordance to the stratification we perform in the proceeding cell"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we will perform this step counterintuitively before any data preprocessing, this is even more so a peculiar decision as we are denying ourselves modularity - as our data preprocessing will have to be coded with the specific features that have dropped in mind when applying various means of preprocessing. We are doing this as the most efficient way to perform this feature selection is to store our data as a pandas dataframe, sk-learn understandbly does not support this datastructure in its machine learning, so to not undergo too many data conversions, we will perform this step now, and proceed with the dropped features in mind."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we instantiate a copy of our dataset to train models on that uses feature selection, we will code a function that computes the absoloute value of correlation, and if that is below a certain threshold we drop the column from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1818,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def drop_correlation_columns(data, threshold):\n",
    "#     features_to_drop = list(\n",
    "#         dataset.corr()[abs(dataset.corr()['Y']) < threshold].index)\n",
    "#     print('Dropping following labels: ', features_to_drop)\n",
    "#     data.drop(features_to_drop, axis=1, inplace=True)\n",
    "#     return data\n",
    "\n",
    "# train_dropped = drop_correlation_columns(train_set, 0.25)\n",
    "# test_dropped = drop_correlation_columns(test_set, 0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1819,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# as already discussed 'x0' is a categorical feature of the dataset, \n",
    "# thus we need to use one-hot encoding to convert the feature into a numerical representation\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "onehot_X0 = encoder.fit_transform(dataset['X0'].values.reshape(-1, 1))\n",
    "dataset = dataset.drop('X0', axis=1)\n",
    "dataset = pd.concat([dataset, pd.DataFrame(onehot_X0)], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1820,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'x3' has missing values, so we need to impute the missing values before we can use it, as already deduced in the notebook\n",
    "# we will use the median value to impute the missing values\n",
    "\n",
    "median_X3 = dataset['X3'].median()\n",
    "dataset['X3'].fillna(median_X3, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1821,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "\n",
    "# split the dataset into train and test sets,\n",
    "# note: we are using X[4] as our target variable, this is the the 'OverallHeight' feature, we stratify based upon this feature, as it has \n",
    "# the highest correlation with the target variable\n",
    "\n",
    "# convert X to a pandas dataframe so we can use the loc function\n",
    "for train_index, test_index in stratified_split.split(dataset, dataset['X5']):\n",
    "    train_set = dataset.loc[train_index]\n",
    "    test_set = dataset.loc[test_index]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1822,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the features\n",
    "train_set.columns = train_set.columns.astype(str)\n",
    "test_set.columns = test_set.columns.astype(str)\n",
    "train_scaler = StandardScaler()\n",
    "test_scaler = StandardScaler()\n",
    "train_set = train_scaler.fit_transform(train_set)\n",
    "test_set = test_scaler.fit_transform(test_set)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1823,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.delete(train_set, 9, axis=1)\n",
    "y_train = train_set[:, 9]\n",
    "X_test = np.delete(test_set, 9, axis=1)\n",
    "y_test = test_set[:, 9]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiating our models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for us, the sklearn API provides a GridSearchCV class, allowing us to iterate through a list of pipelines and models, evaluating their performance against one another, to find the optimal choice for the problem at hand; hyper parameters can also be deliberated upon within this process. Furhtermore, all of the models bar one (Polynomial regression) are already created in the sklearn API, so we can simply instantiate them, and pass them into the grid search."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a polynomial regression model with regularisation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, unlike all the other models relevant to this analysis, the polynomial regression model isn't implemented within the sk-learn API. So we must create this manually. To ensure this works with the modularity concepts we have put in place elsewhere within the code, the implementation of this model is done so in accordance to the sk-learn pipeline API. This means that the model can be passed into the grid search, and the hyper parameters can be deliberated upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1824,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REWRITE: Note that we import BaseEstimator and RegressorMixin from sklearn.base, and we define PolynomialRegression as \n",
    "# a subclass of both BaseEstimator and RegressorMixin. This allows us to use PolynomialRegression as a fully-fledged estimator \n",
    "# within the sklearn ecosystem.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class PolynomialRegression(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, degree=2):\n",
    "        self.degree = degree\n",
    "        self.model = Pipeline([\n",
    "            ('poly', PolynomialFeatures(degree=self.degree)),\n",
    "            ('ridge', Ridge(alpha=0.1))\n",
    "        ])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return self.model.score(X, y)\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        for param, value in params.items():\n",
    "            if param.startswith('poly__'):\n",
    "                setattr(self.model.named_steps['poly'], param[len('poly__'):], value)\n",
    "            else:\n",
    "                setattr(self.model, param, value)\n",
    "        return self"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating all other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1825,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'PolynomialRegression': PolynomialRegression()\n",
    "}\n",
    "\n",
    "# we also define a dictionary of hyperparameters to be searched for each respective model,\n",
    "# will be iterated through matching the keys to the models dictionary\n",
    "param_grid = {\n",
    "    'LinearRegression': {},\n",
    "    'Ridge': {'alpha': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0]},\n",
    "    'Lasso': {'alpha': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0]},\n",
    "    'ElasticNet': {'alpha': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0], 'l1_ratio': [0.1, 0.5, 0.9, 1.0]},\n",
    "    'PolynomialRegression': {'polynomialfeatures__degree': [2, 3, 4, 5], 'ridge__alpha': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0]}\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform grid search and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1826,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "trained_models = {}\n",
    "param_results = {}\n",
    "results = []\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    params = param_grid[model_name]\n",
    "    grid_search = GridSearchCV(model, params, scoring='neg_mean_absolute_percentage_error', cv=5, n_jobs=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    trained_models[model_name] = grid_search.best_estimator_\n",
    "    param_results[model_name] = grid_search.best_params_\n",
    "    results.append({\n",
    "        'model': model_name,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'best_params': grid_search.best_params_,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1829,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>-8.422840e-16</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>-4.868050e-05</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PolynomialRegression</td>\n",
       "      <td>-2.426127e-04</td>\n",
       "      <td>{'polynomialfeatures__degree': 2, 'ridge__alph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>-2.033074e-02</td>\n",
       "      <td>{'alpha': 0.01, 'l1_ratio': 0.1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-2.044361e-02</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model    best_score  \\\n",
       "0      LinearRegression -8.422840e-16   \n",
       "1                 Ridge -4.868050e-05   \n",
       "2  PolynomialRegression -2.426127e-04   \n",
       "3            ElasticNet -2.033074e-02   \n",
       "4                 Lasso -2.044361e-02   \n",
       "\n",
       "                                         best_params  \n",
       "0                                                 {}  \n",
       "1                                    {'alpha': 0.01}  \n",
       "2  {'polynomialfeatures__degree': 2, 'ridge__alph...  \n",
       "3                   {'alpha': 0.01, 'l1_ratio': 0.1}  \n",
       "4                                    {'alpha': 0.01}  "
      ]
     },
     "execution_count": 1829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=['best_score'], ascending=False)\n",
    "results_df = results_df.reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on the two best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1831,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9981573907452783"
      ]
     },
     "execution_count": 1831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models['Lasso'].set_params(**param_results['Lasso']).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9981620374030648"
      ]
     },
     "execution_count": 1832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_models['ElasticNet'].set_params(**param_results['ElasticNet']).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
